<!DOCTYPE html>
<html>
<head>
    <meta name="google-site-verification" content="Io5PBEGCOEzWaL7oGOG-6-qHqYLZsvb7vAXvdoEF-1Y" />
    <meta charset="utf-8">
    <meta name="description"
          content="">
    <meta name="keywords" content="Grasp Detection, Multi-Scale Features, Contrastive Learning, Grasp Learning">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>MISCGrasp</title>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']], processEscapes: true}, "HTML-CSS": {minScaleAdjust: 100} });
    </script>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-PYVRSFMDRL');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
          rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <!-- <link rel="icon" href="./static/images/favicon.png"> -->

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
    <link rel="icon" href="./static/images/icon.jpg" type="image/png">
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
        <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
        </a>
    </div>
    <div class="navbar-menu">
        <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
            <a class="navbar-item" href="https://fanqyu.github.io/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
            </a>

            <!--      <div class="navbar-item has-dropdown is-hoverable">-->
            <!--        <a class="navbar-link">-->
            <!--          More Related Research-->
            <!--        </a>-->
            <!--        <div class="navbar-dropdown">-->
            <!--          <a class="navbar-item" href="https://pointw.github.io/equi_rl_page/">-->
            <!--            Equivairant Reinforcement Learning-->
            <!--          </a>-->
            <!--          <a class="navbar-item" href="https://pointw.github.io/equi_q_page/">-->
            <!--            Equivariant Q-Learning-->
            <!--          </a>-->
            <!--          <a class="navbar-item" href="https://pointw.github.io/equi_robot_page/">-->
            <!--            On Robot Equivariant Learning-->
            <!--          </a>-->
            <!--          <a class="navbar-item" href="https://pointw.github.io/extrinsic_page/">-->
            <!--            Extrinsic Equivariance-->
            <!--          </a>-->
            <!--        </div>-->
            <!--      </div>-->
        </div>

    </div>
</nav>


<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">MISCGrasp: Leveraging Multiple Integrated Scales and Contrastive Learning for Enhanced Volumetric Grasping </h1>
                    <div class="is-size-5 publication-authors">
                        <span class="author-block">
                          <a href="https://fanqyu.github.io/">Qingyu Fan</a><sup>1,2</sup>,
                        </span>
                        <span class="author-block">
                          <a href="https://sites.google.com/site/caiyinghao">Yinghao Cai</a><sup>1,2†</sup>,
                        </span>
                        <span class="author-block">
                          Chao Li<sup>3</sup>,
                        </span>
                        <span class="author-block">
                          Chunting Jiao<sup>3</sup>,
                        </span>
                        <span class="author-block">
                          Xudong Zheng<sup>3</sup>,
                        </span>   
                        <span class="author-block">
                          Tao Lu<sup>1</sup>,
                        </span>
                        <span class="author-block">
                          <a href="https://scholar.google.com/citations?hl=en&user=mpchz3sAAAAJ&view_op=list_works&sortby=pubdate ">Bin Liang</a><sup>3</sup>,
                        </span>
                        <span class="author-block">
                          <a href="https://scholar.google.com/citations?user=XL9j2UUAAAAJ&hl=en">Shuo Wang</a><sup>1,2</sup>
                        </span>  
                    </div>

                   <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences</span><br>
                    <span class="author-block"><sup>2</sup>School of Artificial Intelligence, University of Chinese Academy of Sciences</span><br>
                    <span class="author-block"><sup>3</sup>Qiyuan Lab</span>
                    <div>
                        <span class="author-block" style="color: gray;">† corresponding author</span>
                    </div>
                  </div>


                <div class="column has-text-centered">
                    <div class="publication-links">
                      <!-- PDF Link. -->
                      <span class="link-block">
                        <a href="PAPER_URL"
                           class="external-link button is-normal is-rounded is-dark">
                          <span class="icon">
                              <i class="fas fa-file-pdf"></i>
                          </span>
                          <span>Paper</span>
                        </a>
                      </span>
                      <span class="link-block">
                        <a href="ARXIV_URL"
                           class="external-link button is-normal is-rounded is-dark">
                          <span class="icon">
                              <i class="ai ai-arxiv"></i>
                          </span>
                          <span>arXiv</span>
                        </a>
                      </span>
                      <!-- Video Link. -->
                      <span class="link-block">
                        <a href="https://youtu.be/KXRjxByu6hM"
                           class="external-link button is-normal is-rounded is-dark">
                          <span class="icon">
                              <i class="fab fa-youtube"></i>
                          </span>
                          <span>Video</span>
                        </a>
                      </span>
                      <!-- Code Link. -->
                      <span class="link-block">
                        <a href="https://github.com/Fanqyu/MiscGrasp"
                           class="external-link button is-normal is-rounded is-dark">
                          <span class="icon">
                              <i class="fab fa-github"></i>
                          </span>
                          <span>Code</span>
                          </a>
                      </span>
                      <!-- Dataset Link. -->
                      <span class="link-block">
                        <a href="https://github.com/Fanqyu/MiscGrasp"
                           class="external-link button is-normal is-rounded is-dark">
                          <span class="icon">
                              <i class="far fa-images"></i>
                          </span>
                          <span>Data</span>
                          </a>
                    </div>
                  </div>
                
                </div>
            </div>
        </div>
    </div>
</section>


<section class="hero is-light is-small">
    <div class="hero-body">
        <div class="container">
            <div id="results-carousel" class="carousel results-carousel">

                <div class="item item-demo1">
                    <video poster="" id="demo1" autoplay controls muted loop playsinline height="5%">
                        <source src="./static/video/all_cmprs.mp4"
                                type="video/mp4">
                    </video>
                </div>

                <div class="item item-demo2">
                    <video poster="" id="demo2" autoplay controls muted loop playsinline height="5%">
                        <source src="./static/video/small_cmprs.mp4"
                                type="video/mp4">
                    </video>
                </div>

                <div class="item item-demo3">
                    <video poster="" id="demo3" autoplay controls muted loop playsinline height="5%">
                        <source src="./static/video/large_cmprs.mp4"
                                type="video/mp4">
                    </video>
                </div>
            </div>
        </div>
    </div>
</section>

<!-- <section class="hero is-light is-small">
    <div class="hero-body">
        <div class="container">
            <div id="results-carouse1" class="carousel results-carouse1">

                <div class="item item-demo4">
                    <video poster="" id="demo4" autoplay controls muted loop playsinline height="5%">
                        <source src="./static/video/12_cmprs.mp4"
                                type="video/mp4">
                    </video>
                </div>

                <div class="item item-demo5">
                    <video poster="" id="demo5" autoplay controls muted loop playsinline height="5%">
                        <source src="./static/video/13_cmprs.mp4"
                                type="video/mp4">
                    </video>
                </div>

                <div class="item item-demo6">
                    <video poster="" id="demo6" autoplay controls muted loop playsinline height="5%">
                        <source src="./static/video/15_cmprs.mp4"
                                type="video/mp4">
                    </video>
                </div>

                <div class="item item-demo7">
                    <video poster="" id="demo7" autoplay controls muted loop playsinline height="5%">
                        <source src="./static/video/16_cmprs.mp4"
                                type="video/mp4">
                    </video>
                </div>

                <div class="item item-demo8">
                    <video poster="" id="demo8" autoplay controls muted loop playsinline height="5%">
                        <source src="./static/video/20_cmprs.mp4"
                                type="video/mp4">
                    </video>
                </div>
                
                <div class="item item-demo9">
                    <video poster="" id="demo9" autoplay controls muted loop playsinline height="5%">
                        <source src="./static/video/3_cmprs.mp4"
                                type="video/mp4">
                    </video>
                </div>

                <div class="item item-demo10">
                    <video poster="" id="demo10" autoplay controls muted loop playsinline height="5%">
                        <source src="./static/video/4_cmprs.mp4"
                                type="video/mp4">
                    </video>
                </div>

                <div class="item item-demo11">
                    <video poster="" id="demo11" autoplay controls muted loop playsinline height="5%">
                        <source src="./static/video/6_cmprs.mp4"
                                type="video/mp4">
                    </video>
                </div>

                <div class="item item-demo12">
                    <video poster="" id="demo12" autoplay controls muted loop playsinline height="5%">
                        <source src="./static/video/9_cmprs.mp4"
                                type="video/mp4">
                    </video>
                </div>
            </div>
        </div>
    </div>
</section> -->

<section class="section">
    <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                      <p align="center">
                        <img src="./static/images/fig1_300.png" alt="" style="width:70%"></img>
                    </p>
<!--                     <p>
                        While grasp detection is an important part of any robotic manipulation pipeline, reliable and
                        accurate grasp detection in $SE(3)$ remains a research challenge. Many robotics applications in
                        unstructured environments such as the home or warehouse would benefit a lot from better grasp
                        performance. This paper proposes a novel framework for detecting $SE(3)$ grasp poses based on
                        point cloud input. Our main contribution is to propose an $SE(3)$-equivariant model that maps
                        each point in the cloud to a continuous grasp quality function over the 2-sphere $S^2$ using a
                        spherical harmonic basis. Compared with reasoning about a finite set of samples, this
                        formulation improves the accuracy and efficiency of our model when a large number of samples
                        would otherwise be needed. In order to accomplish this, we propose a novel variation on
                        EquiFormerV2 that leverages a UNet-style encoder-decoder architecture to enlarge the number of
                        points the model can handle. Our resulting method, which we name $\textit{OrbitGrasp}$,
                        significantly outperforms baselines in both simulation and physical experiments.
                    </p> -->
                </div>
            </div>
        </div>
        <!--/ Abstract. -->

        <!-- Paper video. -->
        <!-- <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Video</h2>
            <div class="publication-video">
              <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                      frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
            </div>
          </div>
        </div> -->
        <!--/ Paper video. -->
    </div>
</section>

<section class="section">
    <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
            <div class="column">
                <h2 class="title is-3">Introduction</h2>
                <div class="content has-text-justified">
<!--                     <p>
                        In this paper, we propose $\textbf{OrbitGrasp}$, an $SE(3)$-equivariant grasp learning framework
                        using spherical harmonics for 6-DoF grasp detection. Our method leverages
                        an $SE(3)$-equivariant network that maps each point in a point cloud to a grasp quality
                        function over the 2-sphere $S^2$. For each point in the cloud, this function
                        encodes the grasp quality for possible hand approach directions toward that point.
                        By applying geometric constrains, we reduce the action space to an $\textit{orbit}$ (i.e.,
                        an $S^1$ manifold embedded in $S^2$) of approach directions, defined relative to the
                        surface normal at each contact point. As shown below:
                    </p>
                    <p>
                        We infer an orbit of grasps (yellow ellipse) defined relative to the surface normal (red arrow)
                        at the contact point (pink dot). Since our model is equivariant over $SO(3)$, the optimal pose
                        (represented by the solid gripper) on the orbit rotates consistently with the scene (left and
                        right show a rotation by 90 degrees).
                    </p> -->
                    <p align="center">
                        <img src="./static/images/fig2_300.png"></img>
                    </p>
<!--                     <p>
                        OrbitGrasp divides the input point cloud into several sub-point clouds $B_i$ (neighborhoods
                        around center points $c_i$) and processes each through the network and
                        outputs a grasp quality function $f_p\colon S^2 \to \mathbb{R}$ for each point $p$ in $B_i$. The
                        model produces Fourier coefficients for each $p$ (represented as different channels in the
                        network output), which are used to reconstruct $f_p$ based on spherical harmonics. The Orbit
                        Pose Sampler generates multiple poses for each $p$ perpendicular to the surface normal $n_p$ and
                        queries corresponding $f_p(\cdot)$ to evaluate these grasp qualities along the orbit. The grasp
                        with the highest quality is then selected, thereby producing the optimal grasp pose $a^*$, as
                        shown on the right.
                    </p> -->

                </div>
            </div>
        </div>
    </div>
</section>

<section class="section">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column">
                <h2 class="title is-3">Simulation Experiments</h2>
                <div class="content has-text-justified">
                    <p>
                        We conduct four grasping experiments using four object sets: the EGAD test set, the pile and packed 
                        test set, and the adversarial object set. These experiments focus on both pinch and power grasps across 
                        two scene type: <strong>Pile</strong> and <strong>Packed</strong>. The <strong>EGAD-Single</strong> experiment scales the EGAD test set 
                        to 147 objects, ranked by geometric complexity and grasp difficulty, and evaluates performance on easy, 
                        medium, and hard sets. The <strong>Pile-Pile</strong> and <strong>Packed-Packed</strong> experiments use the pile and packed test 
                        sets with 10 objects per scene, increasing complexity. The <strong>EGAD+Adv-Pile</strong> experiment combines the 
                        EGAD test set and adversarial object set to test pinch grasp in pile scenes with 10 objects per scene.
                    </p>
                </div>
                <div class="column is-centered">
                    <img src="./static/images/sim_type.png" style="width:100%"></img>
                </div>

                <div class="content has-text-centered">
                    <p>
                        $\textbf{Visualization of EGAD+ADV-Pile}$
                    </p>
                </div>

                <div class="columns is-centered">
                    <div class="column is-centered">
                        <div class="video-container">
                            <video class="center" playsinline="" autoplay="" loop="" muted=""
                                   src="./static/video/egad+adv-pile_27.mp4" style="border-radius:10px;"></video>

                        </div>
                    </div>
                    <div class="column is-centered">
                        <div class="video-container">
                            <video class="center" playsinline="" autoplay="" loop="" muted=""
                                   src="./static/video/egad+adv-pile_78.mp4" style="border-radius:10px;"></video>

                        </div>
                    </div>
                    <div class="column is-centered">
                        <div class="video-container">
                            <video class="center" playsinline="" autoplay="" loop="" muted=""
                                   src="./static/video/egad+adv-pile_79.mp4" style="border-radius:10px;"></video>

                        </div>
                    </div>
                </div>

                <div class="content has-text-centered">
                    <p>
                        $\textbf{Visualization of Pile-Pile}$
                    </p>
                </div>

                <div class="columns is-centered">
                    <div class="column is-centered">
                        <div class="video-container">
                            <video class="center" playsinline="" autoplay="" loop="" muted=""
                                   src="./static/video/pile-pile_39.mp4" style="border-radius:10px;"></video>

                        </div>
                    </div>
                    <div class="column is-centered">
                        <div class="video-container">
                            <video class="center" playsinline="" autoplay="" loop="" muted=""
                                   src="./static/video/pile-pile_74.mp4" style="border-radius:10px;"></video>

                        </div>
                    </div>
                    <div class="column is-centered">
                        <div class="video-container">
                            <video class="center" playsinline="" autoplay="" loop="" muted=""
                                   src="./static/video/pile-pile_76.mp4" style="border-radius:10px;"></video>

                        </div>
                    </div>

                </div>
                
                <div class="content has-text-centered">
                    <p>
                        $\textbf{Visualization of Packed-Packed}$
                    </p>
                </div>

                <div class="columns is-centered">

                    <div class="column is-centered">
                        <div class="video-container">
                            <video class="center" playsinline="" autoplay="" loop="" muted=""
                                   src="./static/video/packed-packed_28.mp4" style="border-radius:10px;"></video>
                        </div>
                    </div>
                    <div class="column is-centered">
                        <div class="video-container">
                            <video class="center" playsinline="" autoplay="" loop="" muted=""
                                   src="./static/video/packed-packed_61.mp4" style="border-radius:10px;"></video>
                        </div>
                    </div>
                    <div class="column is-centered">
                        <div class="video-container">
                            <video class="center" playsinline="" autoplay="" loop="" muted=""
                                   src="./static/video/packed-packed_76.mp4" style="border-radius:10px;"></video>
                        </div>
                    </div>

                </div>

<!--                 <div class="column is-centered">
                    <img src="./static/images/sim_result.png"></img>
                </div>
                <div class="content has-text-justified">
                    <p>
                        We compared the OrbitGrasp with various baselines in terms of grasp success rate (GSR) and
                        declutter rate (DR). OrbitGrasp (3M) is trained on the downsampled 3M dataset. OrbitGrasp (6M)
                        is trained on
                        the full 6M dataset.
                        The results indicate that our method outperforms all
                        baselines across both settings and tasks in terms of both GSR and DR, in both the 3M and 6M
                        training sets. The high GSR indicates that our model can predict accurate grasp quality. On the
                        other hand, the high DR signifies that our model infers accurate grasp poses that do not move
                        objects outside of the workspace.
                    </p>
                </div>
            </div> -->
        </div>
    </div>
</section>

<section class="section">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column">
                <h2 class="title is-3">Physical Experiments</h2>
                <div class="content has-text-justified">
                    <p>
                        Our experimental platform uses a UR5 robotic arm with a Robotiq 2-Finger 85 gripper, and grasp planning is 
                        performed in a 0.4 × 0.4 × 0.4 m<sup>3</sup> workspace, with perception from an Intel RealSense 
                        D435 depth sensor. We conduct both single-object and multi-object grasping experiments. Single-object tests 
                        involve five EGAD objects 3D-printed at three sizes (3 cm, 6 cm, 9 cm) for power and pinch grasps. Multi-object 
                        experiments include 9 EGAD objects, 14 Berkeley adversarial objects, 30 household items, and the single-object 
                        set, all tested in pile scenarios to optimize resources and time. Each test is repeated 20 times with 10 objects per round.
                    </p>
                </div>
                <div class="column is-centered" style="margin-top: -20px;">
                    <img src="./static/images/real_obj.png"></img>
                </div>
<!--                 <div class="content has-text-centered" style="margin-top: 30px;">
                    <p>
                        $\textbf{Result Visualization}$
                    </p>
                </div>

                <div class="columns is-centered">
                    <div class="column is-centered">
                        <div class="video-container">
                            <video class="center" controls="" playsinline="" autoplay="" loop="" muted=""
                                   src="./static/video/packed1.mp4" style="border-radius:10px;"></video>
                            <p style="text-align: center; font-size: 18px">Packed Scene 1</p>
                        </div>
                    </div>
                    <div class="column is-centered">
                        <div class="video-container">
                            <video class="center" controls="" playsinline="" autoplay="" loop="" muted=""
                                   src="./static/video/packed2.mp4" style="border-radius:10px;"></video>
                            <p style="text-align: center; font-size: 18px">Packed Scene 2</p>
                        </div>
                    </div>
                </div>

                <div class="columns is-centered">
                    <div class="column is-centered">
                        <div class="video-container">
                            <video class="center" controls="" playsinline="" autoplay="" loop="" muted=""
                                   src="./static/video/pile1.mp4" style="border-radius:10px;"></video>
                            <p style="text-align: center; font-size: 18px">Pile Scene 1</p>
                        </div>
                    </div>
                    <div class="column is-centered">
                        <div class="video-container">
                            <video class="center" controls="" playsinline="" autoplay="" loop="" muted=""
                                   src="./static/video/pile2.mp4" style="border-radius:10px;"></video>
                            <p style="text-align: center; font-size: 18px">Pile Scene 2</p>
                        </div>
                    </div>
                    <div class="column is-centered">
                        <div class="video-container">
                            <video class="center" controls="" playsinline="" autoplay="" loop="" muted=""
                                   src="./static/video/pile3.mp4" style="border-radius:10px;"></video>
                            <p style="text-align: center; font-size: 18px">Pile Scene 3</p>
                        </div>
                    </div>


                </div>
                <div class="content has-text-centered" style="margin-top: 40px;">
                    <p>We compared the results of OrbitGrasp with VNEdgeGrasp using the same metrics as in the
                        simulation experiments.
                    </p>
                </div>
                <div class="content has-text-centered">
                    <p>
                        $\textbf{Quantitative Results}$
                    </p>
                </div>
                <div class="column is-centered" style="margin-top: -25px;">
                    <img src="./static/images/real_result.png"></img>
                </div> -->
                
            </div>
        </div>
    </div>
</section>


<section class="section">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column">
                <h2 class="title is-3">Video</h2>
                <center>
                    <iframe width="840" height="472.5"
                            src="https://www.youtube.com/embed/KXRjxByu6hM?si=yowKuLocTjzotdZS"
                            title="YouTube video player" frameborder="0"
                            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                            referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
                </center>
            </div>
        </div>
    </div>
</section>

<!-- <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
        <h3 class="title">Citation</h3>
        <pre><code>
@inproceedings{
   huorbitgrasp,
   title={OrbitGrasp: SE (3)-Equivariant Grasp Learning},
   author={Hu, Boce and Zhu, Xupeng and Wang, Dian and Dong, Zihao and Huang, Haojie and Wang, Chenghao and Walters, Robin and Platt, Robert},
   booktitle={8th Annual Conference on Robot Learning},
   year={2024},
   url={https://openreview.net/forum?id=clqzoCrulY}
}
    </code></pre>
    </div>
</section> -->
    
<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      
    <!-- Concurrent Work. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Acknowledgements</h2>

        <div class="content has-text-justified">
          <p>
              Thanks to the authors of <a href="https://github.com/ethz-asl/vgn">VGN</a> for making their work publicly available. <br>
              Also, thanks to Boce, the creator of <a href="https://orbitgrasp.github.io/">OribitGrasp</a>, for sharing screen recording tips.
          </p>
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->

  </div>
</section>


<footer class="footer">
    <div class="container">

        <div class="columns is-centered">
            <div class="column is-8">
                <div class="content">
                    <p>
                       This website template is borrowed from <a href="https://github.com/nerfies/nerfies.github.io">NeRFies</a>.
                    </p>
                </div>
            </div>
        </div>
    </div>
</footer>

</body>
</html>
